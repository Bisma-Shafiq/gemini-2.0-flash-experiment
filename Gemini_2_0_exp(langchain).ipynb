{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMwdpHVweJynvw47nVx2Yo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bisma-Shafiq/gemini-2.0-flash-experiment/blob/main/Gemini_2_0_exp(langchain).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WfPQd4cIPbCk",
        "outputId": "b2985440-226a-45f3-ecb4-8f6210f4e7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.25)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.10.3)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-genai) (2.27.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (11.0.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.28.1 in /usr/local/lib/python3.10/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.0dev,>=13.0 in /usr/local/lib/python3.10/dist-packages (from google-genai) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (4.9)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2024.12.14)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-genai) (0.6.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-google-genai google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Key setup\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY: str = userdata.get('GOOGLE_API_KEY')\n",
        "if(GOOGLE_API_KEY):\n",
        "  print(\"API Key found\")\n",
        "else:\n",
        "  print(\"API Key not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhPVzB-jQpR4",
        "outputId": "d2a1ba63-28d2-44f7-d8ad-b1df9334fe43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import Client\n",
        "client: Client = genai.Client(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "GkxjwjMTQLlJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai.types import GenerateContentResponse\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "dUJHPvJpfP02"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model : str = \"gemini-2.0-flash-exp\"\n",
        "response:GenerateContentResponse= client.models.generate_content(model = model ,contents =\"what is ai in 10 words?\")\n"
      ],
      "metadata": {
        "id": "tVUgCtRmQlw5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "x1thZy-YfwNH",
        "outputId": "99aa008a-f1b2-4cda-849f-91feeccaf40a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Machines mimicking human intelligence to solve problems.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini 2.0 with langchain"
      ],
      "metadata": {
        "id": "AsKs9ZzYgBvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI , GoogleGenerativeAI"
      ],
      "metadata": {
        "id": "HV-yWqsif0WW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = GoogleGenerativeAI(model=model , google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "pxPABeOik_LN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_model.invoke(\"what is Agentic RAG in 10 words\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLOgV2N2lkAJ",
        "outputId": "f7353359-fe72-4b06-d255-f1ca3b4c9b01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autonomous, iterative retrieval and generation for complex tasks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This module is designed for building chat-based interactions with Google's Gemini models. It's suitable for:\n",
        "Multi-turn conversations: When you need to maintain context and history across multiple interactions with the model.\n",
        "\n",
        "Chatbot development: It provides tools for managing conversation state and generating responses within a chat-like environmen"
      ],
      "metadata": {
        "id": "rGD9LgXQmJNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model = model,google_api_key = GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "QV7h74D6h5oz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"what is Agentic RAG in 10 words\")\n",
        "display(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cydih7wmiHJ4",
        "outputId": "2be3d135-3190-4cd3-d536-40955d01ed86"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Autonomous agents enhance retrieval and generation in RAG systems.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"what is AI in 10 words\")\n",
        "display(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CW8E3ObciSfJ",
        "outputId": "8f9e76bb-2f28-4d94-82a9-b0ebe85f2c62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Machines mimicking human intelligence to perform tasks, learn, adapt.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Template and Chain"
      ],
      "metadata": {
        "id": "bGhcyRaZmPsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "jJsX6jJvmfXN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"You are a nice and helpful assistant. Please answer the following question:\\n\\n{question}\"\n",
        ")\n",
        "\n",
        "# Create the LLM chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "2pJ1_Y_QmZcN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain with a sample question\n",
        "question = \"What is RAG vs Agentic RAG? in table form\"\n",
        "response = chain.run({\"question\": question})\n",
        "\n",
        "print(\"Answer:\",response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aJCgCx6mdX1",
        "outputId": "2ca6a2b5-ad45-4270-f54a-428f8122d97f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Okay, I'd be happy to help! Here's a table comparing RAG (Retrieval-Augmented Generation) and Agentic RAG:\n",
            "\n",
            "| Feature           | RAG (Retrieval-Augmented Generation)                                                                          | Agentic RAG                                                                                                                               |\n",
            "|--------------------|-------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| **Core Concept**   | Enhances LLM responses by retrieving relevant information from an external knowledge source.                  | Extends RAG by incorporating autonomous agents that can perform complex reasoning, planning, and tool use in conjunction with retrieval. |\n",
            "| **Process Flow**  | 1. **Query:** User inputs a question.  2. **Retrieval:** Relevant documents are retrieved. 3. **Augmentation:**  Retrieved context is added to the prompt. 4. **Generation:** LLM generates a response. | 1. **Query:** User inputs a question. 2. **Planning:** An agent plans the steps to answer the question. 3. **Retrieval:** Agent retrieves relevant information. 4. **Reasoning/Tool Use:** Agent may reason over retrieved content or use external tools. 5. **Generation:** LLM generates a response based on the agent's actions. |\n",
            "| **Complexity**     | Relatively simple and straightforward.                                                                     | More complex, involving multiple steps and potential interactions between agents and tools.                                              |\n",
            "| **Reasoning**      | Limited reasoning capabilities, relies primarily on the LLM's inherent reasoning on augmented context.         | Enhanced reasoning capabilities by leveraging agents to break down complex tasks and perform step-by-step reasoning.                     |\n",
            "| **Tool Usage**      | Generally does not incorporate external tools beyond retrieval mechanisms.                                  | Can seamlessly integrate and utilize various external tools (e.g., search engines, calculators, APIs) to gather additional information or perform actions. |\n",
            "| **Planning**       | No explicit planning, the process is typically a direct retrieval and generation.                              | Incorporates planning capabilities, allowing the system to strategize and execute multi-step processes to achieve a goal.                |\n",
            "| **Adaptability**   | Less adaptable to complex or multi-faceted queries that require multiple steps.                              | More adaptable to complex tasks, can adjust its approach based on the query and available resources.                                       |\n",
            "| **Use Cases**       | Answering questions based on a specific knowledge base, summarizing documents, content generation.          | Complex question answering, data analysis, task automation, multi-step reasoning, decision-making tasks.                               |\n",
            "| **Example Scenario**|  Retrieving information about a product from a company's documentation to answer a user's question about it. |  Planning a trip by researching destinations, booking flights and hotels, and making recommendations based on user preferences, involving external APIs and tools. |\n",
            "| **Key Advantages** | Improved accuracy and relevance by grounding responses in external knowledge.                               | Increased flexibility, adaptability, and ability to handle complex tasks by leveraging agents and tools.                                |\n",
            "| **Key Limitations** | Limited reasoning and planning capabilities, may struggle with complex or multi-faceted queries.             | Increased complexity, potentially higher computational cost, and requires careful design of agents and their interactions.                   |\n",
            "\n",
            "**In Simple Terms:**\n",
            "\n",
            "* **RAG** is like giving an LLM a textbook before it answers your question. It's straightforward and helpful for basic knowledge-based tasks.\n",
            "* **Agentic RAG** is like giving an LLM a team of researchers and tools before it answers your question. It's more powerful and can handle complex tasks that require planning, reasoning, and the use of various resources.\n",
            "\n",
            "I hope this table is helpful! Let me know if you have any other questions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejlMHT9QoPgx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}